{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.2.2-cp38-none-macosx_10_9_x86_64.whl (150.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 150.6 MB 168 kB/s  eta 0:00:01     |█████████████████████████████▌  | 138.9 MB 30.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: sympy in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: fsspec in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: filelock in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from networkx->torch) (4.4.2)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (2.5.2)\n",
      "Requirement already satisfied: tqdm in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (4.50.2)\n",
      "Requirement already satisfied: fsspec in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (0.8.3)\n",
      "Requirement already satisfied: scipy in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (1.5.2)\n",
      "Requirement already satisfied: pyparsing in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (2.4.7)\n",
      "Requirement already satisfied: numpy in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (1.19.2)\n",
      "Requirement already satisfied: aiohttp in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (3.9.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (5.9.8)\n",
      "Requirement already satisfied: jinja2 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (2.11.2)\n",
      "Requirement already satisfied: requests in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (2.24.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch_geometric) (0.23.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from aiohttp->torch_geometric) (20.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from aiohttp->torch_geometric) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0; python_version < \"3.11\" in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from aiohttp->torch_geometric) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from aiohttp->torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from jinja2->torch_geometric) (1.1.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from requests->torch_geometric) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from requests->torch_geometric) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from requests->torch_geometric) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from requests->torch_geometric) (1.25.11)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (2.2.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp38-cp38-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (0.8.3)\n",
      "Requirement already satisfied: filelock in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: sympy in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (1.6.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: networkx in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torch) (2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: numpy in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/Cathryn/anaconda3/lib/python3.8/site-packages (from networkx->torch) (4.4.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# num_classes = 3\n",
    "# edge_index = torch.tensor([[0, 1, 1, 2, 3, 2],\n",
    "#                            [1, 0, 2, 1, 2, 3]], dtype=torch.long)\n",
    "# x = torch.tensor([[], [], [], []], dtype=torch.float)\n",
    "# y = torch.tensor([[0, 1, 0], [0, 0, 1], [1, 0, 1], [1, 0, 0]], dtype=torch.float)\n",
    "# train_mask = torch.tensor([True, True, False, False], dtype=torch.bool)\n",
    "# test_mask = torch.tensor([False, False, True, True], dtype=torch.bool)\n",
    "# x\n",
    "# data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2432, 384], edge_index=[2, 3319], edge_attr=[3319], y=[2432, 71], y_weights=[71], articles=[2432], categories=[71], test_mask=[2432], train_mask=[2432])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "data = torch.load('GNN_data_class_weights.pt')\n",
    "\n",
    "# Assuming 'dataset' is your entire dataset\n",
    "dataset_size = data.x.shape[0]\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(data.x, [train_size, test_size])\n",
    "\n",
    "# Now you can create masks based on the lengths of train_dataset and test_dataset\n",
    "train_mask = torch.zeros(dataset_size, dtype=torch.bool)\n",
    "test_mask = torch.zeros(dataset_size, dtype=torch.bool)\n",
    "train_mask[list(train_dataset.indices)] = True\n",
    "test_mask[list(test_dataset.indices)] = True\n",
    "\n",
    "data.test_mask = test_mask\n",
    "data.train_mask = train_mask\n",
    "num_classes = data.y.shape[1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta al forno\n",
      "Al forno\n",
      "tensor(1.6167)\n"
     ]
    }
   ],
   "source": [
    "node1 = data.edge_index[0][9]\n",
    "node2 = data.edge_index[1][9]\n",
    "print(data.articles[node1])\n",
    "print(data.articles[node2])\n",
    "print(data.edge_attr[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/Users/Cathryn/anaconda3/lib/python3.8/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c45d43b429d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_convert_np\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_embedding_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sprite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_tsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_pbtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_onnx_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_onnx_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/tensorboard/_embedding.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0m_HAS_GFILE_JOIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"join\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeature_column_lib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeature_column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_feature_column\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_ops_stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# =============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_tf_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mInputSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# See b/110718070#comment18 for more details about this import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_v1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtraining_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork_serialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloss_scale_optimizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixed_precision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mHDF5_OBJECT_HEADER_LIMIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/h5py/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0m_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilence_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_conv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_converters\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0m_register_converters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pxd\u001b[0m in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5t.pyx\u001b[0m in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    321\u001b[0m                              \"{!r}\".format(__name__, attr))\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "# tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn\n",
    "\n",
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, hidden_size=128):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.node_embedding = torch.nn.Embedding(num_nodes, hidden_size)\n",
    "        # Initialize the embeddings with small random values\n",
    "        torch.nn.init.normal_(self.node_embedding.weight, std=0.1)\n",
    "        # self.conv1 = torch_geometric.nn.GCNConv(hidden_size, hidden_size)\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(hidden_size, 16)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        # x = self.node_embedding.weight\n",
    "        x = data.x\n",
    "\n",
    "        # x = self.conv1(x, edge_index)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "class GCNModelNodeFeat(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, num_features, hidden_size=128):\n",
    "        super(GCNModelNodeFeat, self).__init__()\n",
    "        # self.conv1 = torch_geometric.nn.GCNConv(hidden_size, hidden_size)\n",
    "        self.conv1 = torch_geometric.nn.GCNConv(num_features, hidden_size)\n",
    "        self.conv2 = torch_geometric.nn.GCNConv(hidden_size, hidden_size)\n",
    "        self.conv3 = torch_geometric.nn.GCNConv(hidden_size, hidden_size)\n",
    "        self.conv4 = torch_geometric.nn.GCNConv(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        # x = self.node_embedding.weight\n",
    "        x = data.x\n",
    "\n",
    "        # x = self.conv1(x, edge_index)\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv4(x, edge_index, edge_attr)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "0 tensor(6.5904, grad_fn=<DivBackward1>)\n",
      "10 tensor(6.5894, grad_fn=<DivBackward1>)\n",
      "20 tensor(6.5818, grad_fn=<DivBackward1>)\n",
      "30 tensor(6.5574, grad_fn=<DivBackward1>)\n",
      "40 tensor(6.5488, grad_fn=<DivBackward1>)\n",
      "50 tensor(6.5196, grad_fn=<DivBackward1>)\n",
      "60 tensor(6.4936, grad_fn=<DivBackward1>)\n",
      "70 tensor(6.4803, grad_fn=<DivBackward1>)\n",
      "80 tensor(6.4590, grad_fn=<DivBackward1>)\n",
      "90 tensor(6.4347, grad_fn=<DivBackward1>)\n",
      "100 tensor(6.4111, grad_fn=<DivBackward1>)\n",
      "110 tensor(6.4130, grad_fn=<DivBackward1>)\n",
      "120 tensor(6.3760, grad_fn=<DivBackward1>)\n",
      "130 tensor(6.3600, grad_fn=<DivBackward1>)\n",
      "140 tensor(6.3492, grad_fn=<DivBackward1>)\n",
      "150 tensor(6.3497, grad_fn=<DivBackward1>)\n",
      "160 tensor(6.3276, grad_fn=<DivBackward1>)\n",
      "170 tensor(6.3213, grad_fn=<DivBackward1>)\n",
      "180 tensor(6.3183, grad_fn=<DivBackward1>)\n",
      "190 tensor(6.3032, grad_fn=<DivBackward1>)\n",
      "200 tensor(6.2976, grad_fn=<DivBackward1>)\n",
      "210 tensor(6.2970, grad_fn=<DivBackward1>)\n",
      "220 tensor(6.2931, grad_fn=<DivBackward1>)\n",
      "230 tensor(6.2824, grad_fn=<DivBackward1>)\n",
      "240 tensor(6.2766, grad_fn=<DivBackward1>)\n",
      "250 tensor(6.2790, grad_fn=<DivBackward1>)\n",
      "260 tensor(6.2705, grad_fn=<DivBackward1>)\n",
      "270 tensor(6.2716, grad_fn=<DivBackward1>)\n",
      "280 tensor(6.2651, grad_fn=<DivBackward1>)\n",
      "290 tensor(6.2612, grad_fn=<DivBackward1>)\n",
      "300 tensor(6.2523, grad_fn=<DivBackward1>)\n",
      "310 tensor(6.2471, grad_fn=<DivBackward1>)\n",
      "320 tensor(6.2490, grad_fn=<DivBackward1>)\n",
      "330 tensor(6.2608, grad_fn=<DivBackward1>)\n",
      "340 tensor(6.2453, grad_fn=<DivBackward1>)\n",
      "350 tensor(6.2434, grad_fn=<DivBackward1>)\n",
      "360 tensor(6.2493, grad_fn=<DivBackward1>)\n",
      "370 tensor(6.2517, grad_fn=<DivBackward1>)\n",
      "380 tensor(6.2465, grad_fn=<DivBackward1>)\n",
      "390 tensor(6.2389, grad_fn=<DivBackward1>)\n",
      "400 tensor(6.2385, grad_fn=<DivBackward1>)\n",
      "410 tensor(6.2445, grad_fn=<DivBackward1>)\n",
      "420 tensor(6.2496, grad_fn=<DivBackward1>)\n",
      "430 tensor(6.2463, grad_fn=<DivBackward1>)\n",
      "440 tensor(6.2448, grad_fn=<DivBackward1>)\n",
      "450 tensor(6.2423, grad_fn=<DivBackward1>)\n",
      "460 tensor(6.2467, grad_fn=<DivBackward1>)\n",
      "470 tensor(6.2363, grad_fn=<DivBackward1>)\n",
      "480 tensor(6.2348, grad_fn=<DivBackward1>)\n",
      "490 tensor(6.2415, grad_fn=<DivBackward1>)\n",
      "500 tensor(6.2397, grad_fn=<DivBackward1>)\n",
      "510 tensor(6.2430, grad_fn=<DivBackward1>)\n",
      "520 tensor(6.2379, grad_fn=<DivBackward1>)\n",
      "530 tensor(6.2396, grad_fn=<DivBackward1>)\n",
      "540 tensor(6.2466, grad_fn=<DivBackward1>)\n",
      "550 tensor(6.2405, grad_fn=<DivBackward1>)\n",
      "560 tensor(6.2384, grad_fn=<DivBackward1>)\n",
      "570 tensor(6.2430, grad_fn=<DivBackward1>)\n",
      "580 tensor(6.2359, grad_fn=<DivBackward1>)\n",
      "590 tensor(6.2326, grad_fn=<DivBackward1>)\n",
      "600 tensor(6.2445, grad_fn=<DivBackward1>)\n",
      "610 tensor(6.2400, grad_fn=<DivBackward1>)\n",
      "620 tensor(6.2370, grad_fn=<DivBackward1>)\n",
      "630 tensor(6.2405, grad_fn=<DivBackward1>)\n",
      "640 tensor(6.2376, grad_fn=<DivBackward1>)\n",
      "650 tensor(6.2358, grad_fn=<DivBackward1>)\n",
      "660 tensor(6.2386, grad_fn=<DivBackward1>)\n",
      "670 tensor(6.2362, grad_fn=<DivBackward1>)\n",
      "680 tensor(6.2353, grad_fn=<DivBackward1>)\n",
      "690 tensor(6.2389, grad_fn=<DivBackward1>)\n",
      "700 tensor(6.2401, grad_fn=<DivBackward1>)\n",
      "710 tensor(6.2294, grad_fn=<DivBackward1>)\n",
      "720 tensor(6.2394, grad_fn=<DivBackward1>)\n",
      "730 tensor(6.2280, grad_fn=<DivBackward1>)\n",
      "740 tensor(6.2319, grad_fn=<DivBackward1>)\n",
      "750 tensor(6.2334, grad_fn=<DivBackward1>)\n",
      "760 tensor(6.2264, grad_fn=<DivBackward1>)\n",
      "770 tensor(6.2280, grad_fn=<DivBackward1>)\n",
      "780 tensor(6.2191, grad_fn=<DivBackward1>)\n",
      "790 tensor(6.2265, grad_fn=<DivBackward1>)\n",
      "800 tensor(6.2228, grad_fn=<DivBackward1>)\n",
      "810 tensor(6.2205, grad_fn=<DivBackward1>)\n",
      "820 tensor(6.2217, grad_fn=<DivBackward1>)\n",
      "830 tensor(6.2218, grad_fn=<DivBackward1>)\n",
      "840 tensor(6.2241, grad_fn=<DivBackward1>)\n",
      "850 tensor(6.2232, grad_fn=<DivBackward1>)\n",
      "860 tensor(6.2256, grad_fn=<DivBackward1>)\n",
      "870 tensor(6.2220, grad_fn=<DivBackward1>)\n",
      "880 tensor(6.2173, grad_fn=<DivBackward1>)\n",
      "890 tensor(6.2212, grad_fn=<DivBackward1>)\n",
      "900 tensor(6.2185, grad_fn=<DivBackward1>)\n",
      "910 tensor(6.2249, grad_fn=<DivBackward1>)\n",
      "920 tensor(6.2205, grad_fn=<DivBackward1>)\n",
      "930 tensor(6.2182, grad_fn=<DivBackward1>)\n",
      "940 tensor(6.2179, grad_fn=<DivBackward1>)\n",
      "950 tensor(6.2198, grad_fn=<DivBackward1>)\n",
      "960 tensor(6.2207, grad_fn=<DivBackward1>)\n",
      "970 tensor(6.2213, grad_fn=<DivBackward1>)\n",
      "980 tensor(6.2172, grad_fn=<DivBackward1>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = GCNModel(len(data.x)).to(device)\n",
    "print(data.x.shape[1])\n",
    "model = GCNModelNodeFeat(len(data.x), data.x.shape[1]).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# sets the model in training mode\n",
    "# When you call model.train(), PyTorch enables features such as dropout and \n",
    "# batch normalization, which are typically used during training but not during inference\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask], weight=data.y_weights)\n",
    "    loss.backward()\n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch, loss)\n",
    "    # writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "    optimizer.step()\n",
    "\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al forno\n",
      "['Deep fried foods', 'Bread stubs', 'Steamed foods']\n",
      "Bacon Explosion\n",
      "['Deep fried foods']\n",
      "Beef Wellington\n",
      "['Deep fried foods', 'Savoury pies', 'Steamed foods']\n",
      "Papas arrugadas\n",
      "['Deep fried foods']\n",
      "Chicken Kiev\n",
      "['Deep fried foods', 'Savoury pies', 'Steamed foods']\n",
      "Chicken tikka\n",
      "['Deep fried foods', 'Savoury pies', 'Steamed foods']\n",
      "Clambake\n",
      "['Deep fried foods']\n",
      "Cordon bleu (dish)\n",
      "['Deep fried foods', 'Steamed foods']\n",
      "Frikkadel\n",
      "['Sweet breads', 'Deep fried foods', 'Savoury pies', 'Bread stubs', 'Steamed foods']\n",
      "German baked apples\n",
      "['Deep fried foods', 'Bread stubs']\n",
      "Gratin\n",
      "['Deep fried foods', 'Savoury pies', 'Steamed foods']\n",
      "Kolach (bread)\n",
      "['Sweet breads']\n",
      "Kugelis\n",
      "['Deep fried foods']\n",
      "Meatloaf\n",
      "['Deep fried foods', 'Bread stubs']\n",
      "Baked milk\n",
      "['Sweet breads', 'Bread stubs', 'Steamed foods']\n",
      "Pasta al forno\n",
      "['Deep fried foods', 'Bread stubs', 'Steamed foods']\n",
      "Pickert\n",
      "['Deep fried foods']\n",
      "Pom (dish)\n",
      "['Deep fried foods', 'Steamed foods']\n",
      "Rumbledethumps\n",
      "['Deep fried foods']\n",
      "Sajji\n",
      "['Deep fried foods', 'Bread stubs']\n",
      "Precision: 0.0970\n",
      "Recall: 0.1335\n",
      "F1 Score: 0.1124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "model.eval()\n",
    "pred = model(data)\n",
    "# Convert probabilities to binary predictions\n",
    "binary_pred = (pred >= 1.0/num_classes).float()\n",
    "\n",
    "for i in range(20):\n",
    "    print(data.articles[i])\n",
    "    boolean_mask = binary_pred[i] == 1.0\n",
    "    filtered_categories = [category for category, mask in zip(data.categories, boolean_mask) if mask]\n",
    "    print(filtered_categories)\n",
    "\n",
    "\n",
    "# Check if each prediction matches the label for each instance\n",
    "correct = (binary_pred[data.test_mask] == data.y[data.test_mask]).sum() / num_classes\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "\n",
    "precision = precision_score(data.y[data.test_mask], binary_pred[data.test_mask], average='micro')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "recall = recall_score(data.y[data.test_mask], binary_pred[data.test_mask], average='micro')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "f1 = f1_score(data.y[data.test_mask], binary_pred[data.test_mask], average='micro')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch_geometric.utils\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "\n",
    "g = torch_geometric.utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "node_list = dict(map(lambda i,j : (i,j) , g.nodes, data.articles))\n",
    "font_size = 6\n",
    "\n",
    "degrees = dict(g.degree).values()\n",
    "node_size = [(d+1) * 50 for d in degrees]\n",
    "\n",
    "idx = 0\n",
    "for n, l in node_list.items():\n",
    "    node_list[n] = l if node_size[idx] > 400 else (l if node_size[idx] > 200 and random.rand() > 0.95 else (l if random.rand() > 0.85 else ''))\n",
    "    idx += 1\n",
    "\n",
    "pred_list = [p.tolist() for p in pred]\n",
    "node_pred = [float(p.index(max(p))) for p in pred_list]\n",
    "node_color = [colormaps['tab20'](p/num_classes) for p in node_pred]\n",
    "\n",
    "fig = plt.figure(1, figsize=(12, 10), dpi=100)\n",
    "nx.draw(g, labels=node_list, pos=nx.spring_layout(g, k=0.2, iterations=50), font_size=font_size, node_size=node_size, node_color=node_color)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
